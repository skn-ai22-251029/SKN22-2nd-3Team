{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8bfdd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...\n",
      "ëª¨ë¸ í•™ìŠµ ë° ìµœì í™” ì‹œì‘...\n",
      "RandomForest ìµœì í™” ì¤‘...\n",
      "  - RandomForest Accuracy: 0.9445, F1: 0.8871\n",
      "XGBoost ìµœì í™” ì¤‘...\n",
      "  - XGBoost Accuracy: 0.9460, F1: 0.8861\n",
      "LightGBM ìµœì í™” ì¤‘...\n",
      "  - LightGBM Accuracy: 0.9485, F1: 0.8896\n",
      "CatBoost ìµœì í™” ì¤‘...\n",
      "  - CatBoost Accuracy: 0.9525, F1: 0.8973\n",
      "ìµœì¢… ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ì¤‘...\n",
      "ìµœì ì˜ ì„ê³„ê°’ íƒìƒ‰ ì¤‘...\n",
      "----------------------------------------\n",
      "ğŸš€ ìµœì  ì„ê³„ê°’ ë°œê²¬: 0.34\n",
      "ìµœì¢… Accuracy: 0.9500\n",
      "ìµœì¢… F1-Score: 0.8971\n",
      "----------------------------------------\n",
      "ëª¨ë¸ ë° ì ìˆ˜ ì €ì¥ ì™„ë£Œ.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import sklearn.utils.validation\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "# [ë³€ê²½ 1] ì¼ë°˜ SMOTE ëŒ€ì‹  ê²½ê³„ì„  ë°ì´í„°ë¥¼ ì§‘ì¤‘ ê³µëµí•˜ëŠ” BorderlineSMOTE ì‚¬ìš©\n",
    "from imblearn.over_sampling import BorderlineSMOTE \n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "print(\"ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...\")\n",
    "df = pd.read_csv('data/spotify_churn_dataset.csv')\n",
    "\n",
    "# ë¶ˆí•„ìš”í•œ ID ì»¬ëŸ¼ ì œê±°\n",
    "if 'user_id' in df.columns:\n",
    "    df = df.drop(columns=['user_id'])\n",
    "\n",
    "# Feature Engineering (íŒŒìƒë³€ìˆ˜ ì¶”ê°€)\n",
    "df['ad_burden'] = df['ads_listened_per_week'] / (df['listening_time'] + 1)\n",
    "df['satisfaction_score'] = df['songs_played_per_day'] * (1 - df['skip_rate'])\n",
    "df['time_per_song'] = df['listening_time'] / (df['songs_played_per_day'] + 1)\n",
    "\n",
    "# X, y ë¶„ë¦¬\n",
    "X = df.drop(columns=['is_churned'])\n",
    "y = df['is_churned']\n",
    "\n",
    "# ì»¬ëŸ¼ ë¶„ë¥˜\n",
    "numerical_cols = [\n",
    "    'age', 'listening_time', 'songs_played_per_day', 'skip_rate', \n",
    "    'ads_listened_per_week', 'offline_listening',\n",
    "    'ad_burden', 'satisfaction_score', 'time_per_song'\n",
    "]\n",
    "categorical_cols = ['gender', 'country', 'subscription_type', 'device_type']\n",
    "\n",
    "# ì „ì²˜ë¦¬ê¸°\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# í•™ìŠµ ë°ì´í„° ë¶„ë¦¬\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# [ë³€ê²½ 2] ëª¨ë¸ë³„ ê°€ì¤‘ì¹˜(Weights) ê°•í™” - F1 ì ìˆ˜ë¥¼ ìœ„í•´ ì´íƒˆì(1)ë¥¼ ë” ì¤‘ìš”í•˜ê²Œ ì·¨ê¸‰\n",
    "models_params = {\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42, n_jobs=-1, class_weight='balanced_subsample'), # subsampleë¡œ ë³€ê²½í•˜ì—¬ ë” ì •êµí•˜ê²Œ\n",
    "        \"params\": {\n",
    "            \"classifier__n_estimators\": [500, 1000],\n",
    "            \"classifier__max_depth\": [20, None]\n",
    "        }\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        # scale_pos_weight: ì´íƒˆì(Positive)ì— ê°€ì¤‘ì¹˜ 2ë°° ë¶€ì—¬\n",
    "        \"model\": XGBClassifier(random_state=42, n_jobs=-1, use_label_encoder=False, eval_metric='logloss', scale_pos_weight=2.0),\n",
    "        \"params\": {\n",
    "            \"classifier__n_estimators\": [1000],\n",
    "            \"classifier__learning_rate\": [0.05, 0.1],\n",
    "            \"classifier__max_depth\": [5, 7]\n",
    "        }\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        \"model\": LGBMClassifier(random_state=42, n_jobs=-1, verbose=-1, force_col_wise=True, scale_pos_weight=2.0),\n",
    "        \"params\": {\n",
    "            \"classifier__n_estimators\": [1000],\n",
    "            \"classifier__learning_rate\": [0.05, 0.1]\n",
    "        }\n",
    "    },\n",
    "    \"CatBoost\": {\n",
    "        # SqrtBalanced: F1 Score ìµœì í™”ì— ìœ ë¦¬í•œ ê°€ì¤‘ì¹˜ ì˜µì…˜\n",
    "        \"model\": CatBoostClassifier(random_state=42, verbose=0, allow_writing_files=False, auto_class_weights='SqrtBalanced'),\n",
    "        \"params\": {\n",
    "            \"classifier__iterations\": [1000],\n",
    "            \"classifier__learning_rate\": [0.05, 0.1]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "best_estimators = []\n",
    "metrics_data = {}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# BorderlineSMOTE ì„¤ì •\n",
    "bsmote = BorderlineSMOTE(random_state=42, kind='borderline-1')\n",
    "\n",
    "print(\"ëª¨ë¸ í•™ìŠµ ë° ìµœì í™” ì‹œì‘...\")\n",
    "\n",
    "for name, config in models_params.items():\n",
    "    print(f\"{name} ìµœì í™” ì¤‘...\")\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('smote', bsmote), # ì¼ë°˜ SMOTE -> BorderlineSMOTE êµì²´\n",
    "        ('classifier', config['model'])\n",
    "    ])\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        pipeline, config['params'], n_iter=10, scoring='f1', cv=cv, n_jobs=-1, random_state=42, verbose=0\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    # í‰ê°€\n",
    "    best_model = search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    metrics_data[name] = {'Accuracy': acc, 'F1-Score': f1}\n",
    "    print(f\"  - {name} Accuracy: {acc:.4f}, F1: {f1:.4f}\")\n",
    "    \n",
    "    # ì•™ìƒë¸”ì„ ìœ„í•œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ ë° ëª¨ë¸ ì¬ìƒì„±\n",
    "    best_params_clean = {k.replace('classifier__', ''): v for k, v in search.best_params_.items()}\n",
    "    \n",
    "    if name == \"RandomForest\":\n",
    "        model_instance = RandomForestClassifier(**best_params_clean, random_state=42, n_jobs=-1, class_weight='balanced_subsample')\n",
    "    elif name == \"XGBoost\":\n",
    "        model_instance = XGBClassifier(**best_params_clean, random_state=42, n_jobs=-1, use_label_encoder=False, eval_metric='logloss', scale_pos_weight=2.0)\n",
    "    elif name == \"LightGBM\":\n",
    "        model_instance = LGBMClassifier(**best_params_clean, random_state=42, n_jobs=-1, verbose=-1, force_col_wise=True, scale_pos_weight=2.0)\n",
    "    elif name == \"CatBoost\":\n",
    "        model_instance = CatBoostClassifier(**best_params_clean, random_state=42, verbose=0, allow_writing_files=False, auto_class_weights='SqrtBalanced')\n",
    "        \n",
    "    best_estimators.append((name, model_instance))\n",
    "\n",
    "# ìµœì¢… Voting ì•™ìƒë¸”\n",
    "print(\"ìµœì¢… ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "voting_clf = VotingClassifier(estimators=best_estimators, voting='soft')\n",
    "\n",
    "final_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', bsmote), # ìµœì¢… ë‹¨ê³„ì—ì„œë„ BorderlineSMOTE ì‚¬ìš©\n",
    "    ('classifier', voting_clf)\n",
    "])\n",
    "\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# [ë³€ê²½ 3] ìµœì ì˜ ì„ê³„ê°’(Threshold) ì°¾ê¸° - F1 Score ê·¹ëŒ€í™”ì˜ í•µì‹¬\n",
    "print(\"ìµœì ì˜ ì„ê³„ê°’ íƒìƒ‰ ì¤‘...\")\n",
    "y_pred_proba = final_pipeline.predict_proba(X_test)[:, 1] # ì´íƒˆ í™•ë¥ ë§Œ ì¶”ì¶œ\n",
    "\n",
    "thresholds = np.arange(0.3, 0.7, 0.01) # 0.3 ~ 0.7 ì‚¬ì´ë¥¼ 0.01 ë‹¨ìœ„ë¡œ ê²€ì‚¬\n",
    "best_thresh = 0.5\n",
    "best_f1_val = 0\n",
    "best_acc_val = 0\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_pred_temp = (y_pred_proba >= thresh).astype(int)\n",
    "    f1_temp = f1_score(y_test, y_pred_temp)\n",
    "    \n",
    "    if f1_temp > best_f1_val:\n",
    "        best_f1_val = f1_temp\n",
    "        best_acc_val = accuracy_score(y_test, y_pred_temp)\n",
    "        best_thresh = thresh\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼ ì ìš©\n",
    "final_acc = best_acc_val\n",
    "final_f1 = best_f1_val\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"ğŸš€ ìµœì  ì„ê³„ê°’ ë°œê²¬: {best_thresh:.2f}\")\n",
    "print(f\"ìµœì¢… Accuracy: {final_acc:.4f}\")\n",
    "print(f\"ìµœì¢… F1-Score: {final_f1:.4f}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# ì €ì¥\n",
    "if not os.path.exists('models'): os.makedirs('models')\n",
    "# ì£¼ì˜: pipeline ìì²´ëŠ” predict_probaë¥¼ ë±‰ìœ¼ë¯€ë¡œ, ë‚˜ì¤‘ì— ë¶ˆëŸ¬ì˜¬ ë•Œ threshold ë¡œì§ì„ ë”°ë¡œ ì¨ì•¼ í•¨\n",
    "# ì—¬ê¸°ì„œëŠ” ëª¨ë¸ ê°ì²´ë§Œ ì €ì¥\n",
    "joblib.dump(final_pipeline, 'models/spotify_churn_model.pkl')\n",
    "\n",
    "# ë©”íŠ¸ë¦­ ì €ì¥ (JSON)\n",
    "metrics_file = 'data/model_metrics.json'\n",
    "final_metrics = {}\n",
    "if os.path.exists(metrics_file):\n",
    "    try:\n",
    "        with open(metrics_file, 'r') as f:\n",
    "            final_metrics = json.load(f)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# ë©”íŠ¸ë¦­ì— ì„ê³„ê°’ ì •ë³´ë„ ê°™ì´ ì €ì¥í•˜ë©´ ì¢‹ìŒ\n",
    "metrics_data['Voting Ensemble (ML)'] = {\n",
    "    'Accuracy': final_acc, \n",
    "    'F1-Score': final_f1,\n",
    "    'Best Threshold': float(best_thresh)\n",
    "}\n",
    "final_metrics.update(metrics_data)\n",
    "\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump(final_metrics, f, indent=4)\n",
    "\n",
    "print(\"ëª¨ë¸ ë° ì ìˆ˜ ì €ì¥ ì™„ë£Œ.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_basic_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

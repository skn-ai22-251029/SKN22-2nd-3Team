{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6dffd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤...\n",
      "ğŸ¤– ëª¨ë¸ ë° ë©”íŠ¸ë¦­ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...\n",
      "ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ ì‹œê°í™” ìƒì„± ì¤‘...\n",
      "ğŸ” íŠ¹ì„± ì¤‘ìš”ë„ ë°±ë¶„ìœ¨ ê³„ì‚° ì¤‘... (ì‹œê°„ì´ ë‹¤ì†Œ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)\n",
      "\n",
      "==================================================\n",
      "âœ… ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "ğŸ“ ì €ì¥ ìœ„ì¹˜: c:\\Workspaces\\SKN22-2nd-3Team\\JangWansik\\images\n",
      "1. rf_confusion_matrix.png\n",
      "2. dnn_confusion_matrix.png\n",
      "3. model_roc_comparison.png\n",
      "4. importance_comparison_percentage.png\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, f1_score\n",
    "\n",
    "# 1. í™˜ê²½ ì„¤ì • ë° ê²½ë¡œ ì •ì˜\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì • (Windows: Malgun Gothic, Mac: AppleGothic)\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# [ê²½ë¡œ ìˆ˜ì •] notebooks ìƒìœ„ -> 02_training_report -> images\n",
    "IMAGE_DIR = '../02_training_report/images'\n",
    "if not os.path.exists(IMAGE_DIR):\n",
    "    os.makedirs(IMAGE_DIR)\n",
    "\n",
    "# [ê²½ë¡œ ìˆ˜ì •] notebooks ìƒìœ„ -> data / 03_trained_model\n",
    "DATA_PATH = '../data/spotify_churn_dataset.csv'\n",
    "MODEL_DIR = '../03_trained_model'\n",
    "\n",
    "RF_MODEL_PATH = os.path.join(MODEL_DIR, 'spotify_churn_model.pkl')\n",
    "DL_MODEL_PATH = os.path.join(MODEL_DIR, 'spotify_dl_model.h5')\n",
    "DL_PRE_PATH = os.path.join(MODEL_DIR, 'dl_preprocessor.pkl')\n",
    "METRICS_PATH = os.path.join(MODEL_DIR, 'model_metrics.json')\n",
    "\n",
    "# 2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "print(\"ğŸ“Š ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤...\")\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    print(f\"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DATA_PATH}\")\n",
    "    # (ì‹¤ìŠµìš©) íŒŒì¼ì´ ì—†ìœ¼ë©´ ì˜ˆì™¸ ì²˜ë¦¬ ë˜ëŠ” ì¢…ë£Œ\n",
    "else:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "    # ê°€ì„¤ ê¸°ë°˜ íŠ¹ì„± ê³µí•™ (í•™ìŠµ ì‹œì™€ ë™ì¼í•˜ê²Œ ì ìš©)\n",
    "    df['ad_burden'] = df['ads_listened_per_week'] / (df['listening_time'] + 1)\n",
    "    df['satisfaction_score'] = df['songs_played_per_day'] * (1 - df['skip_rate'])\n",
    "    df['time_per_song'] = df['listening_time'] / (df['songs_played_per_day'] + 1)\n",
    "\n",
    "    if 'user_id' in df.columns:\n",
    "        df = df.drop(columns=['user_id'])\n",
    "\n",
    "    X = df.drop(columns=['is_churned'])\n",
    "    y = df['is_churned']\n",
    "\n",
    "    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬ (í•™ìŠµ ì‹œì™€ ë™ì¼í•œ random_state ì‚¬ìš©)\n",
    "    _, X_test, _, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # 3. ëª¨ë¸ ë° ì„±ëŠ¥ ì§€í‘œ ë¡œë“œ\n",
    "    print(\"ğŸ¤– ëª¨ë¸ ë° ë©”íŠ¸ë¦­ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...\")\n",
    "    rf_model = joblib.load(RF_MODEL_PATH)\n",
    "    dl_model = tf.keras.models.load_model(DL_MODEL_PATH)\n",
    "    dl_pre = joblib.load(DL_PRE_PATH)\n",
    "\n",
    "    with open(METRICS_PATH, 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "\n",
    "    # ìµœì  ì„ê³„ê°’ ê°€ì ¸ì˜¤ê¸°\n",
    "    rf_thresh = metrics.get('RandomForest', {}).get('Best Threshold', 0.5)\n",
    "    dnn_thresh = metrics.get('Deep Learning (DNN)', {}).get('Best Threshold', 0.5)\n",
    "\n",
    "    # --- ê³µí†µ ì‹œê°í™” í•¨ìˆ˜ ---\n",
    "    def save_plot(filename):\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(IMAGE_DIR, filename))\n",
    "        plt.close()\n",
    "\n",
    "    # 4. ì„±ëŠ¥ ë¶„ì„ (í˜¼ë™ í–‰ë ¬ & ROC ê³¡ì„ )\n",
    "    print(\"ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ ì‹œê°í™” ìƒì„± ì¤‘...\")\n",
    "\n",
    "    # [ì˜ˆì¸¡ í™•ë¥  ê³„ì‚°]\n",
    "    rf_probs = rf_model.predict_proba(X_test)[:, 1]\n",
    "    X_test_scaled = dl_pre.transform(X_test)\n",
    "    dnn_probs = dl_model.predict(X_test_scaled, verbose=0).flatten()\n",
    "\n",
    "    # [í˜¼ë™ í–‰ë ¬ - Random Forest]\n",
    "    cm_rf = confusion_matrix(y_test, (rf_probs >= rf_thresh).astype(int))\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens')\n",
    "    plt.title(f'Confusion Matrix: Random Forest (Thresh: {rf_thresh:.2f})')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    save_plot('rf_confusion_matrix.png')\n",
    "\n",
    "    # [í˜¼ë™ í–‰ë ¬ - DNN]\n",
    "    cm_dnn = confusion_matrix(y_test, (dnn_probs >= dnn_thresh).astype(int))\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm_dnn, annot=True, fmt='d', cmap='Purples')\n",
    "    plt.title(f'Confusion Matrix: DNN (Thresh: {dnn_thresh:.2f})')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    save_plot('dnn_confusion_matrix.png')\n",
    "\n",
    "    # [ROC ê³¡ì„  ë¹„êµ]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for probs, name, color in zip([rf_probs, dnn_probs], ['Random Forest', 'DNN'], ['green', 'purple']):\n",
    "        fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "        plt.plot(fpr, tpr, color=color, lw=2, label=f'{name} (AUC = {auc(fpr, tpr):.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    plt.title('ROC Curve Comparison')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "    save_plot('model_roc_comparison.png')\n",
    "\n",
    "    # 5. íŠ¹ì„± ì¤‘ìš”ë„ ë°±ë¶„ìœ¨(%) ë¶„ì„\n",
    "    print(\"ğŸ” íŠ¹ì„± ì¤‘ìš”ë„ ë°±ë¶„ìœ¨ ê³„ì‚° ì¤‘... (ì‹œê°„ ì†Œìš”ë¨)\")\n",
    "\n",
    "    def get_importance_pct(model_type):\n",
    "        importances = {}\n",
    "        if model_type == 'RF':\n",
    "            base_f1 = f1_score(y_test, (rf_probs >= rf_thresh).astype(int))\n",
    "        else:\n",
    "            base_f1 = f1_score(y_test, (dnn_probs >= dnn_thresh).astype(int))\n",
    "        \n",
    "        for col in X_test.columns:\n",
    "            X_tmp = X_test.copy()\n",
    "            X_tmp[col] = np.random.permutation(X_tmp[col]) \n",
    "            \n",
    "            if model_type == 'RF':\n",
    "                p = rf_model.predict_proba(X_tmp)[:, 1]\n",
    "                score = f1_score(y_test, (p >= rf_thresh).astype(int))\n",
    "            else:\n",
    "                p = dl_model.predict(dl_pre.transform(X_tmp), verbose=0).flatten()\n",
    "                score = f1_score(y_test, (p >= dnn_thresh).astype(int))\n",
    "            \n",
    "            importances[col] = max(0, base_f1 - score)\n",
    "        \n",
    "        imp_series = pd.Series(importances)\n",
    "        total = imp_series.sum()\n",
    "        if total > 0:\n",
    "            imp_series = (imp_series / total) * 100\n",
    "        return imp_series.sort_values()\n",
    "\n",
    "    rf_imp_pct = get_importance_pct('RF')\n",
    "    dnn_imp_pct = get_importance_pct('DNN')\n",
    "\n",
    "    # [ì¤‘ìš”ë„ ë¹„êµ ì‹œê°í™”]\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "    # Random Forest Chart\n",
    "    rf_imp_pct.plot(kind='barh', ax=ax1, color='forestgreen')\n",
    "    ax1.set_title('Random Forest Feature Importance (%)')\n",
    "    for i, v in enumerate(rf_imp_pct):\n",
    "        ax1.text(v + 0.3, i, f'{v:.1f}%', va='center', fontsize=10)\n",
    "\n",
    "    # DNN Chart\n",
    "    dnn_imp_pct.plot(kind='barh', ax=ax2, color='slateblue')\n",
    "    ax2.set_title('DNN Feature Importance (%)')\n",
    "    for i, v in enumerate(dnn_imp_pct):\n",
    "        ax2.text(v + 0.3, i, f'{v:.1f}%', va='center', fontsize=10)\n",
    "\n",
    "    save_plot('importance_comparison_percentage.png')\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"âœ… ë¶„ì„ ì™„ë£Œ!\")\n",
    "    print(f\"ğŸ“ ì´ë¯¸ì§€ ì €ì¥ ìœ„ì¹˜: {os.path.abspath(IMAGE_DIR)}\")\n",
    "    print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_basic_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8bfdd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "[RandomForest] ëª¨ë¸ ìµœì í™” ì¤‘...\n",
      "[XGBoost] ëª¨ë¸ ìµœì í™” ì¤‘...\n",
      "[LightGBM] ëª¨ë¸ ìµœì í™” ì¤‘...\n",
      "[CatBoost] ëª¨ë¸ ìµœì í™” ì¤‘...\n",
      "ğŸ† ìµœì¢… ì„ ì • ëª¨ë¸: RandomForest (ê²°ê³¼ ì €ì¥ ì™„ë£Œ)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from imblearn.over_sampling import BorderlineSMOTE \n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "data_path = '../data/spotify_churn_dataset.csv'\n",
    "model_save_path = '../models/spotify_churn_model.pkl'\n",
    "metrics_path = '../data/model_metrics.json'\n",
    "\n",
    "print(\"ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "df = pd.read_csv(data_path)\n",
    "if 'user_id' in df.columns: df = df.drop(columns=['user_id'])\n",
    "\n",
    "# í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§\n",
    "df['ad_burden'] = df['ads_listened_per_week'] / (df['listening_time'] + 1)\n",
    "df['satisfaction_score'] = df['songs_played_per_day'] * (1 - df['skip_rate'])\n",
    "df['time_per_song'] = df['listening_time'] / (df['songs_played_per_day'] + 1)\n",
    "\n",
    "X = df.drop(columns=['is_churned'])\n",
    "y = df['is_churned']\n",
    "\n",
    "# ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„í• \n",
    "numerical_cols = ['age', 'listening_time', 'songs_played_per_day', 'skip_rate', 'ads_listened_per_week', 'offline_listening', 'ad_burden', 'satisfaction_score', 'time_per_song']\n",
    "categorical_cols = ['gender', 'country', 'subscription_type', 'device_type']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 4ê°€ì§€ ëª¨ë¸ì— ëŒ€í•´ ê²½ìŸ ì‹œì‘\n",
    "models_params = {\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42, n_jobs=-1, class_weight='balanced_subsample'),\n",
    "        \"params\": {\"classifier__n_estimators\": [300, 500], \"classifier__max_depth\": [10, 20]}\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": XGBClassifier(random_state=42, n_jobs=-1, eval_metric='logloss', scale_pos_weight=2.0),\n",
    "        \"params\": {\"classifier__n_estimators\": [500, 1000], \"classifier__learning_rate\": [0.05]}\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        \"model\": LGBMClassifier(random_state=42, n_jobs=-1, verbose=-1, scale_pos_weight=2.0),\n",
    "        \"params\": {\"classifier__n_estimators\": [500, 1000], \"classifier__learning_rate\": [0.05]}\n",
    "    },\n",
    "    \"CatBoost\": {\n",
    "        \"model\": CatBoostClassifier(random_state=42, verbose=0, auto_class_weights='SqrtBalanced'),\n",
    "        \"params\": {\"classifier__iterations\": [500, 1000], \"classifier__learning_rate\": [0.05]}\n",
    "    }\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "bsmote = BorderlineSMOTE(random_state=42)\n",
    "\n",
    "metrics_data = {}\n",
    "best_model_name = \"\"\n",
    "best_model_score = -1\n",
    "best_model_pipeline = None\n",
    "\n",
    "for name, config in models_params.items():\n",
    "    print(f\"[{name}] ëª¨ë¸ ìµœì í™” ì¤‘...\")\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('smote', bsmote),\n",
    "        ('classifier', config['model'])\n",
    "    ])\n",
    "    \n",
    "    search = RandomizedSearchCV(pipeline, config['params'], n_iter=2, scoring='f1', cv=cv, n_jobs=-1, random_state=42)\n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = search.best_estimator_.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    metrics_data[name] = {\n",
    "        'Accuracy': float(accuracy_score(y_test, y_pred)),\n",
    "        'Recall': float(recall_score(y_test, y_pred)),\n",
    "        'F1-Score': float(f1)\n",
    "    }\n",
    "    \n",
    "    if f1 > best_model_score:\n",
    "        best_model_score = f1\n",
    "        best_model_name = name\n",
    "        best_model_pipeline = search.best_estimator_\n",
    "\n",
    "# ì„ ì •ëœ ìµœê³  ëª¨ë¸ì˜ ì„ê³„ê°’ íŠœë‹\n",
    "y_proba = best_model_pipeline.predict_proba(X_test)[:, 1]\n",
    "final_thresh, final_f1 = 0.5, 0\n",
    "for thresh in np.arange(0.3, 0.7, 0.01):\n",
    "    f1_t = f1_score(y_test, (y_proba >= thresh).astype(int))\n",
    "    if f1_t > final_f1:\n",
    "        final_f1 = f1_t\n",
    "        final_thresh = thresh\n",
    "\n",
    "final_pred = (y_proba >= final_thresh).astype(int)\n",
    "metrics_data[best_model_name].update({\n",
    "    'Accuracy': float(accuracy_score(y_test, final_pred)),\n",
    "    'Recall': float(recall_score(y_test, final_pred)),\n",
    "    'F1-Score': float(final_f1),\n",
    "    'Best Threshold': float(final_thresh)\n",
    "})\n",
    "\n",
    "# ê¸°ì¡´ ë”¥ëŸ¬ë‹ ì ìˆ˜ê°€ ìˆë‹¤ë©´ ìœ ì§€í•˜ë©´ì„œ ì €ì¥\n",
    "if os.path.exists(metrics_path):\n",
    "    try:\n",
    "        with open(metrics_path, 'r') as f:\n",
    "            existing = json.load(f)\n",
    "            if 'Deep Learning (DNN)' in existing:\n",
    "                metrics_data['Deep Learning (DNN)'] = existing['Deep Learning (DNN)']\n",
    "    except: pass\n",
    "\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump(metrics_data, f, indent=4)\n",
    "\n",
    "joblib.dump(best_model_pipeline, model_save_path)\n",
    "print(f\"ğŸ† ìµœì¢… ì„ ì • ëª¨ë¸: {best_model_name} (ê²°ê³¼ ì €ì¥ ì™„ë£Œ)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_basic_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
